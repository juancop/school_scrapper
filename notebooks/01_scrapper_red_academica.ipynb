{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BgIcHiGo6uIl"
      },
      "source": [
        "# Scraper de Red Academica\n",
        "\n",
        "La página redacademica.edu.co contiene un catálogo de colegios en Bogotá, con información también del código DANE. Los nombres de los colegios cuadran bastante bien con los encontrados en el archivo de base de colegios.\n",
        "\n",
        "Este Notebook desarrollará el scraper de esta página web independientemente de los colegios que se encuentran en el archivo de búsqueda. Posteriormente se realizará el emparejamiento de la información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Jkz1SyC6rnU"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import unquote\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "\n",
        "real_academia_url = 'https://www.redacademica.edu.co/colegios?name=&field_localidad_target_id=All&page={idx}'\n",
        "school_base_url = 'https://www.redacademica.edu.co'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Za_iTsjsAvoF"
      },
      "outputs": [],
      "source": [
        "def get_school_batch_urls(idx):\n",
        "  \"\"\"\n",
        "  Permite obtener las URLs de los colegios de la página:\n",
        "\n",
        "  Params\n",
        "  --------\n",
        "\n",
        "    idx: (int):\n",
        "      Un enetero que indica que página de colegios está revisando. (De 1 a 14)\n",
        "\n",
        "  Returns\n",
        "  --------\n",
        "    batch_urls (list):\n",
        "      Un diccionario que contiene la URL de cada colegio de la página\n",
        "  \"\"\"\n",
        "\n",
        "  # Request de Extracción\n",
        "  response = requests.get(real_academia_url.format(**{'idx': idx}))\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  school_elements = soup.find_all(class_='card-school__name')\n",
        "  anchor_elements = soup.find_all('a', class_='card-school__name')\n",
        "\n",
        "  # Extracción de hrefs de colegios\n",
        "  school_links = {}\n",
        "  for anchor in anchor_elements:\n",
        "      school_name = anchor.text.strip()\n",
        "      href = anchor['href']\n",
        "      school_links[school_name] = school_base_url + href\n",
        "\n",
        "  return school_links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dCE_z8BV7eI1"
      },
      "outputs": [],
      "source": [
        "def request_school_info(school_url):\n",
        "  \"\"\"\n",
        "  Permite extraer la información de los colegios en la Information Box.\n",
        "\n",
        "  Params\n",
        "  --------\n",
        "    school_url (str):\n",
        "      La URL del colegio que se va a extraer.\n",
        "\n",
        "  Returns\n",
        "  --------\n",
        "    school_info (dict):\n",
        "      Un diccionario que contiene toda la información que pudo extraerse del colegio.\n",
        "\n",
        "  \"\"\"\n",
        "  response = requests.get(school_url)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  # Extracción de Information Box\n",
        "  school_info_list = soup.find(class_='school-info__list')\n",
        "\n",
        "\n",
        "\n",
        "  school_info = {}\n",
        "  # Procesamiento del body de la página y extracción de información\n",
        "  if school_info_list:\n",
        "      for item in school_info_list.find_all('li', class_='school-info__list-item'):\n",
        "\n",
        "          label = item.find('h4').get_text().strip().lower()\n",
        "\n",
        "          content_list = []\n",
        "          for div in item.find_all('div', class_='field__item'):\n",
        "              content_list.append(div.get_text().strip())\n",
        "\n",
        "          if not content_list:\n",
        "              p_tag = item.find('p')\n",
        "              if p_tag and not p_tag.find('div'):\n",
        "                  content_list.append(p_tag.get_text().strip())\n",
        "              a_tag = item.find('a')\n",
        "              if a_tag:\n",
        "                  href = a_tag['href']\n",
        "                  text = a_tag.get_text(strip=True)\n",
        "                  if 'mailto:' in href:\n",
        "                      content_list.append(unquote(href.split(':', 1)[-1]))\n",
        "                  elif 'tel:' in href:\n",
        "                      content_list.append(text)\n",
        "                  else:\n",
        "                      content_list.append(unquote(a_tag.get_text(strip=True)))\n",
        "\n",
        "\n",
        "          content = ', '.join(content_list) if content_list else None\n",
        "          school_info[label] = content\n",
        "\n",
        "  return school_info"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PtdzwddnCvIV"
      },
      "source": [
        "# Utilización\n",
        "\n",
        "En la sección anterior se desarrolló el código para la extracción de información de los colegios. Es necesario iterar sobre las 15 páginas de listados de colegios para extraer la informción de cada uno de manera individual.\n",
        "\n",
        "Los resultados de la extracción se almacenarán por índice en el archivo `red_academica_information.csv` para su posterior consulta.\n",
        "\n",
        "La extracción se hará con un rezago de 1 segundo para evitar bloqueos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LeNl-EN9Dfxn"
      },
      "outputs": [],
      "source": [
        "output_file = 'red_academica_information.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZZZgfUO7-cQ",
        "outputId": "b72b7362-96a4-4583-c243-4ccab40fbfbd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [06:04<00:00, 24.32s/it]\n"
          ]
        }
      ],
      "source": [
        "for idx in tqdm(range(15)):\n",
        "  school_urls = get_school_batch_urls(idx)\n",
        "  complete_school_extraction = []\n",
        "  for school_name, school_url in school_urls.items():\n",
        "    school_info = request_school_info(school_url)\n",
        "    school_info['nombre'] = school_name\n",
        "    school_info['idx'] = idx\n",
        "    complete_school_extraction.append(school_info)\n",
        "    time.sleep(1)\n",
        "\n",
        "  # Estructuración en Data Frame\n",
        "  df = pd.DataFrame(complete_school_extraction)\n",
        "  df.drop_duplicates(inplace=True)\n",
        "  # Append si existe, y creación en primera iteración\n",
        "  if os.path.isfile(output_file):\n",
        "    df.to_csv(output_file, mode='a', header=False, index=False)\n",
        "  else:\n",
        "    df.to_csv(output_file, mode='w', header=True, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_enap7hbLuMp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
